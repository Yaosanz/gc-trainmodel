{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_weather_data(file_paths_dict):\n",
    "    \"\"\"\n",
    "    Load dan gabungkan data dari berbagai kota dengan coverage area yang lebih luas\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for city, file_path in file_paths_dict.items():\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            \n",
    "        # Ambil koordinat pusat kota\n",
    "        base_lat = float(data['data']['nearest_area'][0]['latitude'])\n",
    "        base_lon = float(data['data']['nearest_area'][0]['longitude'])\n",
    "        \n",
    "        # Buat grid koordinat sekitar kota (radius Â±0.1 derajat)\n",
    "        lat_variations = np.arange(base_lat - 0.1, base_lat + 0.1, 0.05)\n",
    "        lon_variations = np.arange(base_lon - 0.1, base_lon + 0.1, 0.05)\n",
    "        \n",
    "        for day in data['data']['weather']:\n",
    "            date = day['date']\n",
    "            hourly = day['hourly'][0]\n",
    "            \n",
    "            # Generate data untuk berbagai titik koordinat sekitar kota\n",
    "            for lat in lat_variations:\n",
    "                for lon in lon_variations:\n",
    "                    # Tambahkan sedikit variasi untuk data yang lebih realistis\n",
    "                    temp_variation = np.random.uniform(-0.5, 0.5)\n",
    "                    humidity_variation = np.random.uniform(-2, 2)\n",
    "                    \n",
    "                    all_data.append({\n",
    "                        'date': date,\n",
    "                        'city': city,\n",
    "                        'latitude': round(lat, 6),\n",
    "                        'longitude': round(lon, 6),\n",
    "                        'tempC': float(hourly['tempC']) + temp_variation,\n",
    "                        'humidity': float(hourly['humidity']) + humidity_variation,\n",
    "                        'cloudcover': float(hourly['cloudcover']),\n",
    "                        'precipMM': float(hourly['precipMM']),\n",
    "                        'pressure': float(hourly['pressure']),\n",
    "                        'uvIndex': float(hourly['uvIndex'])\n",
    "                    })\n",
    "    \n",
    "    return pl.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary kota dan file path\n",
    "cities_data = {\n",
    "    'Bogor': '/kaggle/input/kota-bogor.json',\n",
    "    'Jakarta': '/kaggle/input/jakarta.json',\n",
    "    'Bekasi': '/kaggle/input/bekasi.json',\n",
    "    'Depok': '/kaggle/input/depok.json',\n",
    "    'Tangerang': '/kaggle/input/kota-tangerang.json',\n",
    "    'Tangerang-Selatan': '/kaggle/input/tangsel.json',\n",
    "    'Kabupaten-Bogor': '/kaggle/input/kabupaten-bogor.json',\n",
    "    'Cikarang': '/kaggle/input/cikarang.json'\n",
    "}\n",
    "try:\n",
    "    # Muat data\n",
    "    df = load_weather_data(cities_data)\n",
    "    print(\"Data berhasil dimuat!\")\n",
    "    print(f\"Jumlah baris data: {len(df)}\")\n",
    "    \n",
    "    # Tambahkan fitur temporal\n",
    "    df = df.with_columns([\n",
    "        pl.col('date').str.strptime(pl.Date, format='%Y-%m-%d').dt.ordinal_day().alias('day_of_year'),\n",
    "        pl.col('date').str.strptime(pl.Date, format='%Y-%m-%d').dt.month().alias('month'),\n",
    "        pl.col('date').str.strptime(pl.Date, format='%Y-%m-%d').dt.weekday().alias('weekday')\n",
    "    ])\n",
    "    \n",
    "    # Tampilkan informasi data\n",
    "    print(\"\\nInformasi Data:\")\n",
    "    print(f\"Kolom yang tersedia: {df.columns}\")\n",
    "    print(\"\\nContoh 5 baris pertama:\")\n",
    "    print(df.head())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File tidak ditemukan - {str(e)}\")\n",
    "    print(\"Pastikan semua file JSON tersedia di lokasi yang benar\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memproses data: {str(e)}\")\n",
    "    print(\"Periksa format data dan struktur JSON\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = df.with_columns([\n",
    "    pl.col('date').str.strptime(pl.Date, format='%Y-%m-%d').dt.ordinal_day().alias('day_of_year'),\n",
    "    pl.col('date').str.strptime(pl.Date, format='%Y-%m-%d').dt.month().alias('month'),\n",
    "    pl.col('date').str.strptime(pl.Date, format='%Y-%m-%d').dt.weekday().alias('weekday')\n",
    "])\n",
    "\n",
    "# Persiapkan fitur\n",
    "feature_cols = [\n",
    "    'latitude', 'longitude', 'day_of_year', 'month', 'weekday',\n",
    "    'tempC', 'humidity', 'cloudcover', 'precipMM', 'pressure'\n",
    "]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Cek apakah GPU tersedia\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Setel GPU yang akan digunakan (dalam hal ini gpu:0)\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        print(f\"GPU {gpus[0]} akan digunakan.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Tidak ada GPU yang ditemukan. Model akan berjalan di CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Pisahkan fitur dan target\n",
    "X = df[feature_cols].to_numpy()\n",
    "y = df['uvIndex'].to_numpy()\n",
    "\n",
    "# Normalisasi fitur menggunakan MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Bagi data menjadi training dan testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Pastikan TensorFlow menggunakan GPU yang tersedia\n",
    "physical_devices = tf.config.list_physical_devices('GPU:0')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"GPU tersedia dan digunakan:\", physical_devices[0])\n",
    "else:\n",
    "    print(\"Tidak ada GPU yang tersedia.\")\n",
    "\n",
    "# Bangun model neural network\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Output layer untuk prediksi UV Index\n",
    "])\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Ringkasan model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Callback untuk menghentikan training jika tidak ada peningkatan setelah beberapa epoch\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Latih model dengan GPU P100 (gpu:0)\n",
    "with tf.device('/device:GPU:0'):\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluasi model pada data testing\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "\n",
    "# Prediksi UV Index pada data testing untuk melihat hasilnya secara visual atau statistik.\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def predict_uv_index(model, scaler, city_name, lat, lon, date):\n",
    "    \"\"\"\n",
    "    Prediksi UV Index untuk lokasi dan tanggal tertentu.\n",
    "    \n",
    "    Parameters:\n",
    "        model: Model TensorFlow yang sudah dilatih.\n",
    "        scaler: MinMaxScaler yang sudah di-fit.\n",
    "        city_name: Nama kota (untuk informasi).\n",
    "        lat: Latitude lokasi.\n",
    "        lon: Longitude lokasi.\n",
    "        date: Tanggal dalam format 'YYYY-MM-DD'.\n",
    "    \n",
    "    Returns:\n",
    "        Predicted UV Index.\n",
    "    \"\"\"\n",
    "    # Konversi tanggal ke fitur temporal\n",
    "    date_obj = datetime.strptime(date, '%Y-%m-%d')\n",
    "    day_of_year = date_obj.timetuple().tm_yday\n",
    "    month = date_obj.month\n",
    "    weekday = date_obj.weekday()  # Monday=0, Sunday=6\n",
    "    \n",
    "    # Buat array input untuk prediksi\n",
    "    input_data = np.array([[lat, lon, day_of_year, month, weekday,\n",
    "                            25.0, 70.0, 50.0, 0.0, 1013.25]])  # Nilai default untuk cuaca\n",
    "    \n",
    "    # Normalisasi input data\n",
    "    input_scaled = scaler.transform(input_data)\n",
    "    \n",
    "    # Prediksi UV Index\n",
    "    uv_index_pred = model.predict(input_scaled)[0][0]\n",
    "    \n",
    "    print(f\"Predicted UV Index for {city_name} ({lat}, {lon}) on {date}: {uv_index_pred:.2f}\")\n",
    "    \n",
    "    return uv_index_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Daftar lokasi dan tanggal yang ingin diprediksi\n",
    "locations = [\n",
    "    {\"city\": \"Bogor\", \"lat\": -6.5962986, \"lon\": 106.7972421},\n",
    "    {\"city\": \"Kabupaten Bogor\", \"lat\": -6.5453255, \"lon\": 107.0017425},\n",
    "    {\"city\": \"Depok\", \"lat\": -6.40719, \"lon\": 106.8158371},\n",
    "    {\"city\": \"Tangerang\", \"lat\": -6.1761924, \"lon\": 106.6382161},\n",
    "    {\"city\": \"Tangerang Selatan\", \"lat\": -6.3227016, \"lon\": 106.7085737},\n",
    "    {\"city\": \"Bekasi\", \"lat\": -6.2349858, \"lon\": 106.9945444},\n",
    "    {\"city\": \"Jakarta\", \"lat\": -6.2838182, \"lon\": 106.8048633},\n",
    "    {\"city\": \"Kabupaten Bekasi\", \"lat\": -6.2027897, \"lon\": 107.1649161}\n",
    "]\n",
    "\n",
    "# Tanggal yang ingin diprediksi (contoh: '2025-01-18')\n",
    "target_date = '2025-01-19'\n",
    "\n",
    "# Lakukan prediksi untuk setiap lokasi pada tanggal tersebut\n",
    "for loc in locations:\n",
    "    predict_uv_index(model, scaler,\n",
    "                     city_name=loc[\"city\"],\n",
    "                     lat=loc[\"lat\"],\n",
    "                     lon=loc[\"lon\"],\n",
    "                     date=target_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Simpan model ke file HDF5\n",
    "model.save('uv_index_prediction_model_final.h5')\n",
    "print(\"Model saved as 'uv_index_prediction_model.h5'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
